{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d6a50e7",
   "metadata": {},
   "source": [
    "\n",
    "# Predictive Analysis Using Machine Learning — Classification\n",
    "\n",
    "**Goal:** Build and evaluate a machine learning model to predict outcomes from a dataset, demonstrating **feature selection**, **model training**, and **evaluation**.\n",
    "\n",
    "**Dataset:** Breast Cancer Wisconsin (Diagnostic) — available via scikit-learn.\n",
    "\n",
    "**Outline:**\n",
    "1. Load and explore data\n",
    "2. Split data; create preprocessing & baseline model\n",
    "3. Perform feature selection\n",
    "4. Train tuned models\n",
    "5. Evaluate with metrics & visualizations\n",
    "6. Inspect feature importance and conclude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f7b3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, RocCurveDisplay\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347e14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name=\"target\")\n",
    "\n",
    "X.head(), y.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1d1065",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5273d6",
   "metadata": {},
   "source": [
    "\n",
    "## Baseline Model (No Feature Selection)\n",
    "\n",
    "We'll start with a logistic regression model on all features to establish a baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2ec17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Baseline: Logistic Regression on all features\n",
    "numeric_features = X.columns.tolist()\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[(\"num\", StandardScaler(), numeric_features)],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "baseline_clf = Pipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"clf\", LogisticRegression(max_iter=500, random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "baseline_clf.fit(X_train, y_train)\n",
    "y_pred_base = baseline_clf.predict(X_test)\n",
    "y_prob_base = baseline_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "baseline_metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred_base),\n",
    "    \"Precision\": precision_score(y_test, y_pred_base),\n",
    "    \"Recall\": recall_score(y_test, y_pred_base),\n",
    "    \"F1\": f1_score(y_test, y_pred_base),\n",
    "    \"ROC_AUC\": roc_auc_score(y_test, y_prob_base),\n",
    "}\n",
    "baseline_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9426723d",
   "metadata": {},
   "source": [
    "\n",
    "## Feature Selection\n",
    "\n",
    "We'll use **mutual information** with `SelectKBest` to score features and choose the most informative ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b96f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Try several k values and pick the one with best cross-validated score\n",
    "k_values = [5, 8, 10, 12, 15, 20, X_train.shape[1]]\n",
    "\n",
    "pipe_fs = Pipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"select\", SelectKBest(score_func=mutual_info_classif)),\n",
    "    (\"clf\", LogisticRegression(max_iter=500, random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "param_grid = {\"select__k\": k_values}\n",
    "grid_fs = GridSearchCV(pipe_fs, param_grid=param_grid, cv=5, scoring=\"roc_auc\", n_jobs=-1)\n",
    "grid_fs.fit(X_train, y_train)\n",
    "\n",
    "best_k = grid_fs.best_params_[\"select__k\"]\n",
    "best_k, grid_fs.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7be0022",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit the best feature selection pipeline on the full training set and evaluate\n",
    "best_fs_model = grid_fs.best_estimator_\n",
    "y_pred_fs = best_fs_model.predict(X_test)\n",
    "y_prob_fs = best_fs_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "fs_metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred_fs),\n",
    "    \"Precision\": precision_score(y_test, y_pred_fs),\n",
    "    \"Recall\": recall_score(y_test, y_pred_fs),\n",
    "    \"F1\": f1_score(y_test, y_pred_fs),\n",
    "    \"ROC_AUC\": roc_auc_score(y_test, y_prob_fs),\n",
    "}\n",
    "fs_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f4dd75",
   "metadata": {},
   "source": [
    "\n",
    "## Model Training with an Alternative Classifier\n",
    "\n",
    "We'll also train a **RandomForestClassifier** behind the same preprocessing + feature selection block and tune a couple of key hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66438354",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipe_rf = Pipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"select\", SelectKBest(score_func=mutual_info_classif, k=best_k)),\n",
    "    (\"rf\", RandomForestClassifier(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "param_grid_rf = {\n",
    "    \"rf__n_estimators\": [100, 300],\n",
    "    \"rf__max_depth\": [None, 5, 10],\n",
    "    \"rf__min_samples_split\": [2, 5]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(pipe_rf, param_grid=param_grid_rf, cv=5, scoring=\"roc_auc\", n_jobs=-1)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = grid_rf.best_estimator_.predict(X_test)\n",
    "y_prob_rf = grid_rf.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "\n",
    "rf_metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred_rf),\n",
    "    \"Precision\": precision_score(y_test, y_pred_rf),\n",
    "    \"Recall\": recall_score(y_test, y_pred_rf),\n",
    "    \"F1\": f1_score(y_test, y_pred_rf),\n",
    "    \"ROC_AUC\": roc_auc_score(y_test, y_prob_rf),\n",
    "}\n",
    "\n",
    "grid_rf.best_params_, rf_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6db2f12",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluation: Confusion Matrix & ROC Curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Confusion matrices\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "fig = plt.figure()\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_base)\n",
    "plt.title(\"Confusion Matrix — Baseline Logistic Regression\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_fs)\n",
    "plt.title(\"Confusion Matrix — Logistic Regression with Feature Selection\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_rf)\n",
    "plt.title(\"Confusion Matrix — Random Forest with Feature Selection\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a61ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ROC curves\n",
    "fig = plt.figure()\n",
    "RocCurveDisplay.from_predictions(y_test, y_prob_base)\n",
    "plt.title(\"ROC Curve — Baseline Logistic Regression\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "RocCurveDisplay.from_predictions(y_test, y_prob_fs)\n",
    "plt.title(\"ROC Curve — Logistic Regression with Feature Selection\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "RocCurveDisplay.from_predictions(y_test, y_prob_rf)\n",
    "plt.title(\"ROC Curve — Random Forest with Feature Selection\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5332031b",
   "metadata": {},
   "source": [
    "\n",
    "## Feature Scores and Importances\n",
    "\n",
    "We'll inspect which features were selected and their mutual information scores. For tree-based models, we'll also inspect feature importances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10406477",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get scores from SelectKBest fitted inside the best logistic regression pipeline\n",
    "# Refit SelectKBest on the training data with best_k to extract scores clearly\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=best_k)\n",
    "selector.fit(preprocess.fit_transform(X_train), y_train)\n",
    "\n",
    "selected_mask = selector.get_support()\n",
    "selected_features = np.array(numeric_features)[selected_mask]\n",
    "scores = selector.scores_[selected_mask]\n",
    "\n",
    "feat_scores = pd.DataFrame({\"feature\": selected_features, \"mutual_info\": scores}).sort_values(\"mutual_info\", ascending=False)\n",
    "feat_scores.head(best_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59979e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot mutual information scores\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.barh(feat_scores[\"feature\"], feat_scores[\"mutual_info\"])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Mutual Information Score\")\n",
    "plt.title(\"Top Features by Mutual Information\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5680b65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature importances from RandomForest\n",
    "rf_model = grid_rf.best_estimator_.named_steps[\"rf\"]\n",
    "# Retrieve feature names after selection\n",
    "selected_feature_names = selected_features\n",
    "\n",
    "importances = rf_model.feature_importances_\n",
    "imp_df = pd.DataFrame({\"feature\": selected_feature_names, \"importance\": importances}).sort_values(\"importance\", ascending=False)\n",
    "imp_df.head(best_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7440551",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot RF feature importances\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.barh(imp_df[\"feature\"], imp_df[\"importance\"])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(\"Random Forest Feature Importances\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b48d41a",
   "metadata": {},
   "source": [
    "\n",
    "## Model Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd15ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = pd.DataFrame([\n",
    "    {\"Model\": \"Baseline LogisticRegression (all features)\", **baseline_metrics},\n",
    "    {\"Model\": f\"LogisticRegression + SelectKBest(k={best_k})\", **fs_metrics},\n",
    "    {\"Model\": \"RandomForest + SelectKBest(best k)\", **rf_metrics},\n",
    "])\n",
    "results.sort_values(\"ROC_AUC\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7310af3",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "- We established a strong baseline with Logistic Regression.\n",
    "- Using **feature selection (SelectKBest with mutual information)** helped identify the most informative features and can slightly improve performance and interpretability.\n",
    "- An alternative **Random Forest** model provided a useful comparison; depending on hyperparameters and selected features, it can achieve similar or better ROC AUC.\n",
    "- This notebook demonstrates a full workflow: preprocessing, feature selection, model training, hyperparameter tuning, and evaluation with confusion matrices and ROC curves.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
